dfA$VarIntenCh4 <- 100
predict(modFit, newdata=dfA)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
modFit <- train(Class ~ ., method="rpart", data=training)
print(modFit$finalModel)
dfQuiz1 <- segmentationOriginal[0,]
dfQuiz1[1,1] <- 1
dfQuiz1[1,2] <- "Test"
dfQuiz1[1,3] <- "PS"
for(i in 4:119) dfQuiz1[1,i] <- 0
dfA <- dfQuiz1
dfA$TotalIntench2 <- 23000
dfA$FiberWidthCh1 <- 10
dfA$PerimStatusCh1 <- 2
predict(modFit, newdata=dfA)
dfB <- dfQuiz1
dfB$TotalIntench2 <- 50000
dfB$FiberWidthCh1 <- 10
dfB$VarIntenCh4 <- 100
predict(modFit, newdata=dfB)
dfC <- dfQuiz1
dfC$TotalIntench2 <- 57000
dfC$FiberWidthCh1 <- 8
dfC$VarIntenCh4 <- 100
predict(modFit, newdata=dfC)
dfD <- dfQuiz1
dfD$FiberWidthCh1 <- 8
dfD$VarIntenCh4 <- 100
dfD$PerimStatusCh12 <- 2
predict(modFit, newdata=dfD)
predict(modFit, newdata=testing)
dfQuiz1 <- segmentationOriginal[0,]
dfQuiz1[1,1] <- 1
dfQuiz1[1,2] <- "Test"
dfQuiz1[1,3] <- "PS"
for(i in 4:119) dfQuiz1[1,i] <- NaN
dfA <- dfQuiz1
dfA$TotalIntench2 <- 23000
dfA$FiberWidthCh1 <- 10
dfA$PerimStatusCh1 <- 2
predict(modFit, newdata=dfA)
dfA
dfB <- dfQuiz1
dfB$TotalIntench2 <- 50000
dfB$FiberWidthCh1 <- 10
dfB$VarIntenCh4 <- 100
predict(modFit, newdata=dfB)
library(pgmm)
install.packages("pgmm")
library(pgmm)
olive <- olive[,-1]
data(olive)
olive <- olive[,-1]
str(olive)
install.packages("pgmm")
library(pgmm)
data(olive)
olive <- olive[,-1]
str(olive)
modFit3 <-train(Area ~ ., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
install.packages("pgmm")
data(olive)
olive <- olive[,-1]
str(olive)
modFit3 <-train(Area ~ ., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
data(olive)
olive <- olive[,-1]
str(olive)
modFit3 <-train(Area ~ ., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit3, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
str(SAheart)
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass <= function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
trainSAPredictions <- predict(modelSA, newdata = trainSA)
testSAPredictions <- predict(modelSA, newdata = testSA)
missClass(trainSA$chd,trainSAPredictions)
missClass(testSA$chd, testSAPredictions)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
str(SAheart)
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass <= function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
trainSAPredictions <- predict(modelSA, newdata = trainSA)
testSAPredictions <- predict(modelSA, newdata = testSA)
missClass(trainSA$chd,trainSAPredictions)
missClass(testSA$chd, testSAPredictions)
missClass <= function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
missClass <- function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)
}
trainSAPredictions <- predict(modelSA, newdata = trainSA)
testSAPredictions <- predict(modelSA, newdata = testSA)
missClass(trainSA$chd,trainSAPredictions)
missClass(testSA$chd, testSAPredictions)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modFit5 <-train(y ~ ., method="rf", data=vowel.train, prox="TRUE")
modFit5 <-train(y ~ ., method="rf", data=vowel.train)
modFit5
?varImp
varImp(modFit5)
#Q1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
#http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr
modFit1a <-train(y ~ ., method="rf", data=vowel.train)
modFit1b <-train(y ~ ., method="gbm", data=vowel.train)
predDF <- data.frame(modFit1a, modFit1b, y=vowel.train$y)
combModFit <- train(wage ~ ., method="gam", predDF)
combPred <- predct(combModFit, predDF)
predDF <- data.frame(modFit1a, modFit1b, y=vowel.train$y)
combModFit <- train(wage ~ ., method="gam", predDF)
combPred <- predict(combModFit, predDF)
predDF <- data.frame(modFit1a, modFit1b, y=vowel.train$y)
modFit1a
modFit1b
predDF <- data.frame(modFit1a, modFit1b, y=vowel.train$y)
#Q1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
#http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr
modFit1a <-train(y ~ ., method="rf", data=vowel.train)
modFit1b <-train(y ~ ., method="gbm", data=vowel.train)
pred1 <- predict(modFit1a, vowel.test)
pred2 <- predict(modFit1b, vowel.test)
predDF <- data.frame(pred1, pred2, y=vowel.test$y)
combModFit <- train(wage ~ ., method="gam", predDF)
combPred <- predict(combModFit, predDF)
sqrt(sum(((pred1 - vowel.test$y)^2))
sqrt(sum(((pred2 - vowel.test$y)^2))
sqrt(sum(((combPred - vowel.test$y)^2))
combModFit <- train(y ~ ., method="gam", predDF)
combPred <- predict(combModFit, predDF)
combModFit <- train(y ~ ., method="gam", predDF)
combPred <- predict(combModFit, predDF)
sqrt(sum(((pred1 - vowel.test$y)^2))
sqrt(sum(((pred2 - vowel.test$y)^2))
sqrt(sum(((combPred - vowel.test$y)^2))
sqrt(sum(((pred1 - vowel.test$y)^2))
?sqrt
sqrt(sum((pred1 - vowel.test$y)^2))
pred1
pred2
combPred
vowel.test$y
sqrt(sum((pred1 - vowel.test$y)^2))
sqrt(sum((pred1-vowel.test$y)^2))
ibrary(ElemStatLearn)
data(vowel.train)
data(vowel.test)
#vowel.train$y <- as.factor(vowel.train$y)
#vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
#http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr
modFit1a <-train(y ~ ., method="rf", data=vowel.train)
modFit1b <-train(y ~ ., method="gbm", data=vowel.train)
pred1 <- predict(modFit1a, vowel.test)
pred2 <- predict(modFit1b, vowel.test)
predDF <- data.frame(pred1, pred2, y=vowel.test$y)
combModFit <- train(y ~ ., method="gam", predDF)
combPred <- predict(combModFit, predDF)
sqrt(sum((pred1-vowel.test$y)^2))
sqrt(sum((pred2 - vowel.test$y)^2))
sqrt(sum((combPred - vowel.test$y)^2))
pred1
modFit1a
modFit1b
combModFit
?accuracy
confusionMatrix(vowel.test$y, pred1)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
#vowel.train$y <- as.factor(vowel.train$y)
#vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
#http://www.stat.b
modFit1a <-train(y ~ ., method="rf", data=vowel.train)
confusionMatrix(vowel.test$y, pred1)
pred1
#Q1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
model1 <-train(y ~ ., method="rf", data=vowel.train)
model2 <-train(y ~ ., method="gbm", data=vowel.train)
pred1 <- predict(model1, vowel.test)
pred2 <- predict(model2, vowel.test)
pred1.result
pred1.results
confusionMatrix(vowel.test$y, pred1)
confusionMatrix(pred1, vowel.test$y)$overall[1]
#Q1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model1 <- train(y ~ ., method="rf", data=vowel.train)
model2 <- train(y ~ ., method="gbm", data=vowel.train)
pred1 <- predict(model1, vowel.test)
pred2 <- predict(model2, vowel.test)
confusionMatrix(pred1, vowel.test$y)
confusionMatrix(pred2, vowel.test$y)
confusionMatrix(pred1,vowel.test$y)
confusionMatrix(pred2,vowel.test$y)
agreement <- pred1 == pred2
agreement
confusionMatrix(pred1,vowel.test$y)$overall[1]
confusionMatrix(pred2,vowel.test$y)$overall[1]
agreement <- pred1 == pred2
library(caret)
library(gbm)
library(mgcv)
library(nlme)
library(elasticnet)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
sessionInfo()
install.packages("lubridate")
install.packages("forecast")
install.packages("e1070")
install.packages("e1071")
sessionInfo()
library(lubridate)
library(forecast)
sessionInfo()
pred1
agreement <- pred1 == pred2
predCombined <- data.frame(pred1, pred2, y=vowel.test$y, agreement=agreement)
model3 <- train(y~., predCombined)
pred3 <- predict(model3, vowel.test)
confusionMatrix(pred3, vowel.test$y)$overall[1]
confusionMatrix(pred1,vowel.test$y)$overall[1]
confusionMatrix(pred2,vowel.test$y)$overall[1]
predCombinedDF <- data.frame(pred1, pred2, y=vowel.test$y, agreement=agreement)
model3 <- train(y ~ . , predCombinedDF[agreement,])
pred3 <- predict(model3, vowel.test)
confusionMatrix(pred3, vowel.test$y)$overall[1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model1 <- train(diagnosis ~ ., method="rf", data=training)
model2 <- train(diagnosis ~ ., method="gbm", data=training)
model3 <- train(diagnosis ~ ., method="lda", data=training)
pred1 <- predict(model1, testing)
pred2 <- predict(model2, testing)
pred3 <- predict(model3, testing)
predCombinedDF = data.frame(rf = model1, gbm = model2, lda = model3, diagnosis = training$diagnosis)
model4 = train(diagnosis ~ ., method = 'rf', data = predCombinedDF)
pred4 = predict(model4, testing)
confusionMatrix(pred1,testing$diagnonsis)$overall[1]
confusionMatrix(pred2,testing$diagnonsis)$overall[1]
confusionMatrix(pred3,testing$diagnonsis)$overall[1]
confusionMatrix(pred4,testing$diagnonsis)$overall[1]
predCombinedDF = data.frame(rf = pred1, gbm = pred2, lda = pred3, diagnosis = training$diagnosis)
model4 = train(diagnosis ~ ., method = 'rf', data = predCombinedDF)
pred4 = predict(model4, testing)
confusionMatrix(pred1,testing$diagnonsis)$overall[1]
confusionMatrix(pred2,testing$diagnonsis)$overall[1]
confusionMatrix(pred3,testing$diagnonsis)$overall[1]
confusionMatrix(pred4,testing$diagnonsis)$overall[1]
pred1 <- predict(model1, testing)
pred2 <- predict(model2, testing)
pred3 <- predict(model3, testing)
dim(pre1)
dim(pred1)
dim(pred2)
predict(model1, testing)
predict(model2, testing)
predict(model3, testing)
predCombinedDF = data.frame(rf = pred1, gbm = pred2, lda = pred3, diagnosis = testing$diagnosis)
model4 = train(diagnosis ~ ., method = 'rf', data = predCombinedDF)
pred4 = predict(model4, testing)
confusionMatrix(pred1,testing$diagnonsis)$overall[1]
model4
confusionMatrix(pred1,testing$diagnonsis)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model1 <- train(diagnosis ~ ., method="rf", data=training)
model2 <- train(diagnosis ~ ., method="gbm", data=training)
model3 <- train(diagnosis ~ ., method="lda", data=training)
pred1 <- predict(model1, testing)
pred2 <- predict(model2, testing)
pred3 <- predict(model3, testing)
pred1
predCombinedDF = data.frame(pred1, pred2, pred3, diagnosis = testing$diagnosis)
predCombinedDF
model4 <- train(diagnosis ~ ., method = "rf", data = predCombinedDF)
pred4 <- predict(model4, testing)
confusionMatrix(pred1,testing$diagnosis)$overall[1]
confusionMatrix(pred2,testing$diagnosis)$overall[1]
confusionMatrix(pred3,testing$diagnosis)$overall[1]
confusionMatrix(pred4,testing$diagnosis)$overall[1]
?plot.enet
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model1 <- train(diagnosis ~ ., method="lasso", data=training)
pred1 <- predict(model1, testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model1 <- train(CompressiveStrength ~ ., method="lasso", data=training)
pred1 <- predict(model1, testing)
model1
pred1
?plot.enet
plot.enet(pred1,xvar = c("CompressiveStrength"))
plot.enet(pred1,xvar = c("fraction"))
plot.enet(model1$finalModel, xvar = "penalty", use.color = TRUE)
?forecast.bats
library(lubridate) # For year() function below
dat = read.csv("/Users/smallwes/develop/academic/coursera/datascience/c8-ml/quiz4/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model1 <- bats(tstrain)
plot(forecast(model))
plot(forecast(model1))
?forecast
model1 <- bats(tstrain)
fcast <- forecast(model1, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
model1 <- bats(tstrain)
fcast <- forecast(model1, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
?e1071
library(e1071)
library(e1071)
?e1071
?svm
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model1 <- svm(CompressiveStrength ~ ., data = training)
pred1 <- predict(model1, testing)
accuracy(model1, testing$CompressiveStrength)
library(e1071)
?e1071
?svm
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model1 <- svm(CompressiveStrength ~ ., data = training)
pred1 <- predict(model1, testing)
accuracy(pred1, testing$CompressiveStrength)
setwd("/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/1")
enUSBlogsFilepath -> "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.blogs.txt"
enUSNewsFilepath -> "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.news.txt"
enUSTwitterFilepath -> "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.twitter.txt"
dfBlogs <- read.table(enUSBlogsFilepath,header = FALSE)
enUSBlogsFilepath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.blogs.txt"
enUSNewsFilepath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.news.txt"
enUSTwitterFilepath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.twitter.txt"
dfBlogs <- read.table(enUSBlogsFilepath,header = FALSE)
dfBlogs <- read.table(enUSBlogsFilepath,header = FALSE)
usePackage<-function(p){
# load a package if installed, else load after installation.
# Args: p: package name in quotes
if (!is.element(p, installed.packages()[,1])){
print(paste('Package:',p,'Not found, Installing Now...'))
suppressMessages(install.packages(p, dep = TRUE))
}
print(paste('Loading Package :',p))
require(p, character.only = TRUE)
}
enUSBlogsFilepath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.blogs.txt"
enUSNewsFilepath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.news.txt"
enUSTwitterFilepath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/en_US.twitter.txt"
userPackage("tm")
docBlogs <- Corpus(enUSBlogsFilepath)
usePackage("tm")
docBlogs <- Corpus(enUSBlogsFilepath)
usePackage<-function(p){
# load a package if installed, else load after installation.
# Args: p: package name in quotes
if (!is.element(p, installed.packages()[,1])){
print(paste('Package:',p,'Not found, Installing Now...'))
suppressMessages(install.packages(p, dep = TRUE))
}
print(paste('Loading Package :',p))
require(p, character.only = TRUE)
}
enUSBaseFilePath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/"
enUSBlogsFilepath <- paste0(enUSBaseFilePath,"en_US.blogs.txt")
enUSNewsFilepath <- paste0(enUSBaseFilePath,"en_US.news.txt")
enUSTwitterFilepath <- paste0(enUSBaseFilePath,"en_US.twitter.txt")
df <- read.table(enUSNewsFilepath,header = FALSE)
df <- read.table(enUSNewsFilepath,header = FALSE, sep="\t")
View(df)
file.info(enUSBlogsFilepath)$size / 1024^2
usePackage<-function(p){
# load a package if installed, else load after installation.
# Args: p: package name in quotes
if (!is.element(p, installed.packages()[,1])){
print(paste('Package:',p,'Not found, Installing Now...'))
suppressMessages(install.packages(p, dep = TRUE))
}
print(paste('Loading Package :',p))
require(p, character.only = TRUE)
}
enUSBaseFilePath <- "/Users/smallwes/develop/academic/coursera/datascience/c10-capstone/data/final/en_US/"
enUSBlogsFilepath <- paste0(enUSBaseFilePath,"en_US.blogs.txt")
enUSNewsFilepath <- paste0(enUSBaseFilePath,"en_US.news.txt")
enUSTwitterFilepath <- paste0(enUSBaseFilePath,"en_US.twitter.txt")
file.info(enUSBlogsFilepath)$size / 1024^2
blogs <- readLines("Coursera-Swiftkey/final/en_US/en_US.blogs.txt")
news <- readLines("Coursera-Swiftkey/final/en_US/en_US.news.txt")
twitter <- readLines("Coursera-Swiftkey/final/en_US/en_US.twitter.txt")
blogs <- readLines(enUSBlogsFilepath)
news <- readLines(enUSNewsFilepath)
twitter <- readLines(enUSTwitterFilepath)
head(blogs)
length(twitter)
max(nchar(blogs))
max(nchar(news))
max(nchar(twitter))
lines_with_love <- sum(grepl("love", twitter))
lines_with_hate <- sum(grepl("hate", twitter))
lines_with_love / lines_with_hate
biostats <- grep("biostats", twitter)
twitter[biostats]
grepl("biostats", twitter)
sum(grepl("A computer once beat me at chess, but it was no match for me at kickboxing", twitter))
sum(grepl("A computer once beat me at chess, but it was no match for me at kickboxing", twitter))
